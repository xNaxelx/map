How to use it
Save this file as config.cfg

Make sure you have:

train.spacy and dev.spacy in the current directory

Enough RAM (ideally 8â€“16 GB) for transformer models

Run training:

bash
Copy
Edit
python -m spacy train config.cfg --output ./output --cpu















[system]
seed = 42

[nlp]
lang = "uk"
pipeline = ["transformer", "ner"]
batch_size = 4

[components]

[components.transformer]
factory = "transformer"

[components.transformer.model]
@architectures = "spacy-transformers.TransformerModel.v3"
name = "xlm-roberta-base"
tokenizer_config = {"use_fast": true}
transformer_config = {"output_hidden_states": false}
max_batch_items = 4096

[components.ner]
factory = "ner"

[components.ner.model]
@architectures = "spacy.TransitionBasedParser.v2"
hidden_width = 64
maxout_pieces = 2
use_upper = false
nO = null

[training]
train_corpus = "corpora.train"
dev_corpus = "corpora.dev"
max_epochs = 10
dropout = 0.1
patience = 3
eval_frequency = 200
accumulate_gradient = 2
gradient_clip = 1.0
seed = 42
cpu = true  # Force CPU usage
optimizer = {
  "@optimizers.Adam.v1": {
    "learn_rate": 0.00005,
    "beta1": 0.9,
    "beta2": 0.999,
    "L2_is_weight_decay": true,
    "L2": 0.01
  }
}

[initialize]
vectors = null
init_tok2vec = null

[corpora]

[corpora.train]
@readers = "spacy.Corpus.v1"
path = "./train.spacy"

[corpora.dev]
@readers = "spacy.Corpus.v1"
path = "./dev.spacy"

[pretraining]

[training.logger]
@loggers = "spacy.ConsoleLogger.v1"
progress_bar = true
log_step = 50
